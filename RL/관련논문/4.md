# 제목 

- **[Intelligent mobile robot navigation in unknown and complex environment using reinforcement learning technique](https://www.nature.com/articles/s41598-024-72857-3)**

# 저자

- Ravi Raj, Andrzej Kos

# Abstract

-  강화학습을 활용해 직접 경험을 통해 학습하는 방법으로, 이동 로봇(MRs, Mobile Robots)이 낯선 환경에서도 스스로 길을 찾고 장애물을 회피하면서 목표 지점까지 이동할 수 있는 방법을 제시함.
-  로봇의 움직임과 환경을 수학적 모델로 표현하고, 로봇이 어떤 상황에서 어떤 행동을 해야 하는지를 결정하는 "정책(policy)"을 신경망으로 학습함.
-  시행착오(trial and error)를 통해, 로봇이 환경을 탐험하면서 행동하고, 그 결과에 따라 보상(reward)을 받음
  - 목표 지점에 가까워지면 긍정적 보상
  - 장애물에 부딪히면 부정적 보상
-  사용 알고리즘:
   - Deep Q-Learning(DQN)
     - Q-Learning을 신경망과 결합한 방식
     - 로봇이 "현재 상태에서 어떤 행동을 하면 가장 좋은 결과가 나올까?"를 학습
   - Epsilon-Greedy 전략
     - 학습 중에는 탐험(exploration)과 활용(exploitation)을 균형 있게 수행
     - 대부분은 현재까지 가장 좋은 행동을 선택하지만, 일정 확률($\varepsilon$ )로 새로운 행동을 시도해 더 나은 방법을 찾음
- 로봇은 낯선 환경에서도 스스로 장애물을 회피하고 목표 지점까지 이동할 수 있게 됨
- 시뮬레이션을 통해 기존 방식보다 효율성과 안전성이 향상됨을 확인함.

# Keywords:

- .

# Main contributions of this research

- 환경 또는 로봇 역학에 대한 명시적 모델링이 필요치 않음
- 제어 매개변수를 수동으로 조정할 필요 없이 변화하는 환경과 작업에 적응할 수 있음.
- 경험을 통해 배우고 시간이 지남에 따라 성능을 개선할 수 있음
- 알려지지 않은 환경(unknown environment)에서 이동 로봇을 성공적으로 제어한 연구는 많지 않은데, 본 논문은 종단 간 이동 제어 기술을 제시하여 이전에 논의된 기술의 제약을 극복하고 알려지지 않고 복잡한 환경에서 이동 로봇이 효과적으로 작동할 수 있도록 지원함.

# Limitations

- 제안된 접근법은 시뮬레이션 환경에서 수행되므로 실제 적용 시나리오에 따라 변동이 발생할 수 있음.
- 성능 향상을 위해 향후 보상 함수의 수정 연구가 필요함.
  

# 용어 정리

|용어|설명|
|:-|:-|
